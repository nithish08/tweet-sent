{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of this notebook:\n",
    "\n",
    "1. Load data and do preprocessing for ALBERT model.\n",
    "2. Train the ALBERT model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More about ALBERT:\n",
    "\n",
    "The ALBERT model was proposed in ALBERT: A Lite BERT for Self-supervised Learning of Language Representations by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut. It presents two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT:\n",
    "\n",
    "1. Splitting the embedding matrix into two smaller matrices.\n",
    "1. Using repeating layers split among groups.\n",
    "\n",
    "[link](https://huggingface.co/transformers/model_doc/albert.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "import torch \n",
    "from transformers import AlbertTokenizer, AlbertForQuestionAnswering\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from transformers import AlbertConfig\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tokenizers\n",
    "from transformers import RobertaModel, RobertaConfig\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set gpu id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> download the pretrained weights of alberta model\n",
    "\n",
    "**Run only once**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "for col in ['text', 'selected_text']:\n",
    "    for df in [train, test]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "            df[col] = df[col].apply(lambda x: ' '.join(x.strip().split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download pretrained model\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "# model = AutoModelForQuestionAnswering.from_pretrained(\"albert-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save pretrained model to local directory\n",
    "\n",
    " for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists('pretrained_models/albert-base-v2'):\n",
    "#     os.mkdir('pretrained_models/albert-base-v2')\n",
    "\n",
    "# tokenizer.save_pretrained('pretrained_models/albert-base-v2')\n",
    "# model.save_pretrained('pretrained_models/albert-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pretrained model from local directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how many unknown tokens are there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 14456/571005 -> 2 % unknown tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what's the maximum number of tokens for the padding size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_end_id(question_context_encoded,\n",
    "                    answer_encoded):\n",
    "    '''\n",
    "    Returns Start and end id of tokens of answer in the\n",
    "    given question context vector.\n",
    "    These indices are used as targets for ALBERT QA model.\n",
    "    \n",
    "    Input Args:\n",
    "    \n",
    "        question_context_encoded -> tensor\n",
    "                                    shape = (1, MAX_LEN)\n",
    "                                    \n",
    "        answer_encoded           -> tensor\n",
    "                                    shape = (1, ANSWER_LEN)\n",
    "    \n",
    "    return :\n",
    "    \n",
    "    start_id   ->  tensor with one value\n",
    "    end_id   ->  tensor with one value\n",
    "    '''\n",
    "    \n",
    "    answer_len = answer_encoded.shape[1]\n",
    "    for idx in range(question_context_encoded.shape[1]):\n",
    "        if question_context_encoded[0,idx] == answer_encoded[0,0] and \\\n",
    "        torch.equal(question_context_encoded[0, idx:idx+answer_len].flatten()\n",
    "                    , answer_encoded.flatten()):\n",
    "            return torch.LongTensor([idx]).reshape(1,-1),  \\\n",
    "                        torch.LongTensor([idx+answer_len-1]).reshape(1,-1)\n",
    "    \n",
    "    return torch.LongTensor([0]).reshape(1,1), torch.LongTensor([0]).reshape(1,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, max_len=MAX_LEN):\n",
    "        self.df = df\n",
    "        self.max_len = max_len\n",
    "        self.labeled = 'selected_text' in df.columns\n",
    "        self.tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        data = {}\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "        context  = row.text\n",
    "        question = row.sentiment\n",
    "        \n",
    "        qc_encoded = tokenizer.encode_plus(question,context,\n",
    "                                                         max_length=MAX_LEN,\n",
    "                pad_to_max_length=True, return_tensors='pt')\n",
    "        \n",
    "        for key,value in qc_encoded.items(): # question context encoded tensors\n",
    "            data[key] = value.reshape(-1)\n",
    "            \n",
    "        if self.labeled:\n",
    "            answer   = row.selected_text\n",
    "            answer_encoded = tokenizer.encode_plus(answer,return_tensors='pt',\n",
    "                     add_special_tokens=False)['input_ids']\n",
    "            start_idx, end_idx = get_start_end_id(qc_encoded['input_ids'],\n",
    "                                                 answer_encoded)\n",
    "            data['start_idx'] = start_idx.reshape(-1)\n",
    "            data['end_idx']   = end_idx.reshape(-1)\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_loaders(df, train_idx, val_idx, batch_size=8):\n",
    "    train = df.iloc[train_idx]\n",
    "    val_df = df.iloc[val_idx]\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        TweetDataset(train), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=2,\n",
    "        drop_last=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        TweetDataset(val_df), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=2)\n",
    "\n",
    "    dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n",
    "\n",
    "    return dataloaders_dict\n",
    "\n",
    "def get_test_loader(df, batch_size=32):\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        TweetDataset(df), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=2)    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch lightning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetModel(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(TweetModel, self).__init__()\n",
    "        \n",
    "        self.tokenizer = hparams.tokenizer\n",
    "        self.train_df  = hparams.train_df\n",
    "        self.val_df    = hparams.val_df\n",
    "        self.lr        = hparams.lr\n",
    "        self.batch_size= hparams.batch_size\n",
    "        self.n_workers = hparams.n_workers\n",
    "        \n",
    "        # load albert model\n",
    "        config         = AlbertConfig.from_pretrained(\n",
    "                                    'pretrained_models/albert-base-v2/config.json')\n",
    "        self.model     = AlbertForQuestionAnswering.from_pretrained(\n",
    "                            'pretrained_models/albert-base-v2/pytorch_model.bin', config=config)\n",
    "\n",
    "        # tensorboard purposes\n",
    "        self.train_recorder = 0\n",
    "        self.val_recorder   = 0\n",
    "        \n",
    "        # log hparams\n",
    "#         self.logger.experiment.add_hparams(hparam_dict={'lr':lr},metric_dict={})\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids,\n",
    "               start_positions=None, end_positions=None):\n",
    "        \n",
    "        loss = None\n",
    "        \n",
    "        if start_positions is None:\n",
    "            input_ids      = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            \n",
    "            start_logits, end_logits = self.model.forward(input_ids, attention_mask,\n",
    "                                                         token_type_ids)\n",
    "        else: \n",
    "            input_ids      = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            start_positions= start_positions.to(device)\n",
    "            end_positions  = end_positions.to(device)\n",
    "            \n",
    "            loss, start_logits, end_logits = self.model.forward(input_ids = input_ids,\n",
    "                                                                attention_mask = attention_mask,\n",
    "                                                                token_type_ids = token_type_ids, \n",
    "                                                                start_positions= start_positions,\n",
    "                                                                end_positions  = end_positions)\n",
    "        return loss, start_logits, end_logits\n",
    "        \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, start_logits, end_logits = self.forward(input_ids=batch['input_ids'], \n",
    "                                       attention_mask=batch['attention_mask'], \n",
    "                                       token_type_ids=batch['token_type_ids'],\n",
    "                                       start_positions= batch['start_idx'],\n",
    "                                       end_positions =  batch['end_idx'])\n",
    "        \n",
    "        self.logger.experiment.add_scalar('loss/train',\n",
    "                                          loss.item(),\n",
    "                                          global_step=self.train_recorder)\n",
    "        self.train_recorder += 1  # for tensorboard purposes\n",
    "        \n",
    "        pb = {'train_loss':loss}\n",
    "        return {'loss': loss, 'progress_bar':pb}\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW([p for p in self.parameters() if p.requires_grad],\n",
    "                                 lr=self.lr, betas=(0.9, 0.999))\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        loss, start_logits, end_logits = self.forward(input_ids=batch['input_ids'], \n",
    "                                       attention_mask=batch['attention_mask'], \n",
    "                                       token_type_ids=batch['token_type_ids'],\n",
    "                                       start_positions= batch['start_idx'],\n",
    "                                       end_positions =  batch['end_idx'])\n",
    "        \n",
    "        input_ids = batch['input_ids']\n",
    "        preds = get_batch_predictions(self.tokenizer,\n",
    "                                      input_ids, start_logits, end_logits)\n",
    "        tars  = get_target_text(self.tokenizer, input_ids,\n",
    "                                batch['start_idx'], batch['end_idx'])\n",
    "        \n",
    "        jaccard_score = average_jaccard(tars, preds)\n",
    "        pb = {'val_loss':loss}\n",
    "        return {'val_loss':loss, 'val_jaccard':torch.tensor([jaccard_score]),\n",
    "               'progress_bar':pb}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss    = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_jaccard = torch.stack([x['val_jaccard'] for x in outputs]).mean()\n",
    "        \n",
    "        self.logger.experiment.add_scalar('loss/val', avg_loss.item(), global_step=self.val_recorder)\n",
    "        self.logger.experiment.add_scalar('jaccard/val',avg_jaccard, global_step=self.val_recorder)\n",
    "        self.val_recorder += 1\n",
    "\n",
    "        return {'val_loss':avg_loss, 'val_jaccard':avg_jaccard}\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "                                        TweetDataset(self.val_df), \n",
    "                                        batch_size=self.batch_size, \n",
    "                                        shuffle=False, \n",
    "                                        num_workers=self.n_workers)\n",
    "        return val_loader\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "                                        TweetDataset(self.train_df), \n",
    "                                        batch_size=self.batch_size, \n",
    "                                        shuffle=True, \n",
    "                                        num_workers=self.n_workers)\n",
    "        return train_loader\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_predictions(tokenizer, input_ids, start_logits, end_logits):\n",
    "    '''\n",
    "    \n",
    "    Input Args:\n",
    "    \n",
    "    input_ids    -> (batch_size, max_len)\n",
    "    start_logits -> (batch_size, start_scores)\n",
    "    end_logits   -> (batch_size, end_scores)\n",
    "    \n",
    "    Output:\n",
    "    List[selectec_text]\n",
    "    '''\n",
    "    \n",
    "    input_ids = input_ids.cpu().detach().numpy()\n",
    "    start_logits = start_logits.cpu().detach().numpy()\n",
    "    end_logits = end_logits.cpu().detach().numpy()\n",
    "    \n",
    "    preds = []\n",
    "    for row_id in range(input_ids.shape[0]):\n",
    "        \n",
    "        ids = input_ids[row_id,:]\n",
    "        start = np.argmax(start_logits[row_id,:])\n",
    "        end = np.argmax(end_logits[row_id,:])\n",
    "        \n",
    "        if start>end:\n",
    "            sel_ids = ids  # whole list\n",
    "            \n",
    "        else:\n",
    "            sel_ids = ids[start:end+1]\n",
    "            \n",
    "        text = tokenizer.convert_tokens_to_string(\n",
    "                        tokenizer.convert_ids_to_tokens(sel_ids))\n",
    "        preds.append(text)\n",
    "        \n",
    "    return preds\n",
    "\n",
    "\n",
    "def get_target_text(tokenizer, input_ids, starts, ends):\n",
    "    '''gets the target text given tokenizer \n",
    "    input ids, starts and ends'''\n",
    "    input_ids = input_ids.cpu().detach().numpy()\n",
    "    starts = starts.cpu().detach().numpy().flatten()\n",
    "    ends = ends.cpu().detach().numpy().flatten()\n",
    "    \n",
    "    tars = []\n",
    "    for row_id in range(input_ids.shape[0]):\n",
    "        ids = input_ids[row_id,:]\n",
    "        start, end = starts[row_id], ends[row_id]\n",
    "        text = tokenizer.convert_tokens_to_string(\n",
    "                tokenizer.convert_ids_to_tokens(ids[start:end+1]))\n",
    "        tars.append(text)\n",
    "    \n",
    "    return tars\n",
    "\n",
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def average_jaccard(targets, predictions):\n",
    "    '''get average jaccard for multiple predictions'''\n",
    "    total_score = 0\n",
    "    \n",
    "    for t, p in zip(targets, predictions):\n",
    "        sample_score = jaccard(t, p)\n",
    "        total_score += sample_score\n",
    "    \n",
    "    return total_score/len(targets)  # average\n",
    "\n",
    "def get_total_params(model):\n",
    "    s = 0\n",
    "    for param in model.parameters():\n",
    "        s += param.numel()\n",
    "    return s\n",
    "\n",
    "def get_trainable_params(model):\n",
    "    s = 0\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            s += param.numel()\n",
    "    return s\n",
    "\n",
    "def print_trainable_params(model):\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name)\n",
    "\n",
    "def finetune_model(model, last_n):\n",
    "    '''freezes all the layers in the model except last_n number of layers\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    model  :  pytorch model\n",
    "    last_n    :  number of last layers to unfreeze\n",
    "    '''\n",
    "    \n",
    "    total_layers = len(list(model.parameters()))\n",
    "    \n",
    "    for enum, param in enumerate(model.parameters()):\n",
    "        param.requires_grad = False\n",
    "        if enum + last_n >= total_layers:\n",
    "            param.requires_grad = True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    start_loss = ce_loss(start_logits, start_positions)\n",
    "    end_loss = ce_loss(end_logits, end_positions)    \n",
    "    total_loss = start_loss + end_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 6\n",
    "batch_size = 64\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AlbertTokenizer.from_pretrained('pretrained_models/albert-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "CPU times: user 27.1 ms, sys: 401 µs, total: 27.5 ms\n",
      "Wall time: 26.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train, train.sentiment), start=1): \n",
    "    print(f'Fold: {fold}')\n",
    "    train_df, val_df = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = dict(tokenizer=tokenizer,train_df=train_df, val_df=val_df,\n",
    "                        lr=3e-5, batch_size=64,n_workers=4)\n",
    "\n",
    "hparams = Namespace(**hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TweetModel(\n",
       "  (model): AlbertForQuestionAnswering(\n",
       "    (albert): AlbertModel(\n",
       "      (embeddings): AlbertEmbeddings(\n",
       "        (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 128)\n",
       "        (token_type_embeddings): Embedding(2, 128)\n",
       "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (encoder): AlbertTransformer(\n",
       "        (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "        (albert_layer_groups): ModuleList(\n",
       "          (0): AlbertLayerGroup(\n",
       "            (albert_layers): ModuleList(\n",
       "              (0): AlbertLayer(\n",
       "                (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (attention): AlbertAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0, inplace=False)\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                )\n",
       "                (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (pooler_activation): Tanh()\n",
       "    )\n",
       "    (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_model = TweetModel(hparams)\n",
    "finetune_model(tweet_model, 2)\n",
    "tweet_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "No environment variable for node rank defined. Set as 0.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                                                                             | Type                       | Params\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "0  | model                                                                            | AlbertForQuestionAnswering | 11 M  \n",
      "1  | model.albert                                                                     | AlbertModel                | 11 M  \n",
      "2  | model.albert.embeddings                                                          | AlbertEmbeddings           | 3 M   \n",
      "3  | model.albert.embeddings.word_embeddings                                          | Embedding                  | 3 M   \n",
      "4  | model.albert.embeddings.position_embeddings                                      | Embedding                  | 65 K  \n",
      "5  | model.albert.embeddings.token_type_embeddings                                    | Embedding                  | 256   \n",
      "6  | model.albert.embeddings.LayerNorm                                                | LayerNorm                  | 256   \n",
      "7  | model.albert.embeddings.dropout                                                  | Dropout                    | 0     \n",
      "8  | model.albert.encoder                                                             | AlbertTransformer          | 7 M   \n",
      "9  | model.albert.encoder.embedding_hidden_mapping_in                                 | Linear                     | 99 K  \n",
      "10 | model.albert.encoder.albert_layer_groups                                         | ModuleList                 | 7 M   \n",
      "11 | model.albert.encoder.albert_layer_groups.0                                       | AlbertLayerGroup           | 7 M   \n",
      "12 | model.albert.encoder.albert_layer_groups.0.albert_layers                         | ModuleList                 | 7 M   \n",
      "13 | model.albert.encoder.albert_layer_groups.0.albert_layers.0                       | AlbertLayer                | 7 M   \n",
      "14 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm | LayerNorm                  | 1 K   \n",
      "15 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention             | AlbertAttention            | 2 M   \n",
      "16 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query       | Linear                     | 590 K \n",
      "17 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key         | Linear                     | 590 K \n",
      "18 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value       | Linear                     | 590 K \n",
      "19 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dropout     | Dropout                    | 0     \n",
      "20 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense       | Linear                     | 590 K \n",
      "21 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm   | LayerNorm                  | 1 K   \n",
      "22 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn                   | Linear                     | 2 M   \n",
      "23 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output            | Linear                     | 2 M   \n",
      "24 | model.albert.pooler                                                              | Linear                     | 590 K \n",
      "25 | model.albert.pooler_activation                                                   | Tanh                       | 0     \n",
      "26 | model.qa_outputs                                                                 | Linear                     | 1 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3643eecfed20480ca7a150c83f8b4a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder = trainer.lr_find(tweet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = lr_finder.plot(suggest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_finder.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "No environment variable for node rank defined. Set as 0.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "name = 'albert-feature-extract'\n",
    "logger = TensorBoardLogger(\n",
    "                save_dir='ts-logs',\n",
    "                name = name\n",
    "            )\n",
    "if not os.path.exists('saved_models'):\n",
    "    os.mkdir('saved_models')\n",
    "if not os.path.exists(f'saved_models/{name}'):\n",
    "    os.mkdir(f'saved_models/{name}')\n",
    "checkpoint_callback = ModelCheckpoint(f'saved_models/{name}', save_top_k=2)\n",
    "early_stopping = EarlyStopping(monitor='val_loss')\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10,\n",
    "                     checkpoint_callback=checkpoint_callback,\n",
    "                     logger=logger,\n",
    "                    early_stop_callback=early_stopping,\n",
    "                    auto_lr_find=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                                                                             | Type                       | Params\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "0  | model                                                                            | AlbertForQuestionAnswering | 11 M  \n",
      "1  | model.albert                                                                     | AlbertModel                | 11 M  \n",
      "2  | model.albert.embeddings                                                          | AlbertEmbeddings           | 3 M   \n",
      "3  | model.albert.embeddings.word_embeddings                                          | Embedding                  | 3 M   \n",
      "4  | model.albert.embeddings.position_embeddings                                      | Embedding                  | 65 K  \n",
      "5  | model.albert.embeddings.token_type_embeddings                                    | Embedding                  | 256   \n",
      "6  | model.albert.embeddings.LayerNorm                                                | LayerNorm                  | 256   \n",
      "7  | model.albert.embeddings.dropout                                                  | Dropout                    | 0     \n",
      "8  | model.albert.encoder                                                             | AlbertTransformer          | 7 M   \n",
      "9  | model.albert.encoder.embedding_hidden_mapping_in                                 | Linear                     | 99 K  \n",
      "10 | model.albert.encoder.albert_layer_groups                                         | ModuleList                 | 7 M   \n",
      "11 | model.albert.encoder.albert_layer_groups.0                                       | AlbertLayerGroup           | 7 M   \n",
      "12 | model.albert.encoder.albert_layer_groups.0.albert_layers                         | ModuleList                 | 7 M   \n",
      "13 | model.albert.encoder.albert_layer_groups.0.albert_layers.0                       | AlbertLayer                | 7 M   \n",
      "14 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm | LayerNorm                  | 1 K   \n",
      "15 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention             | AlbertAttention            | 2 M   \n",
      "16 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query       | Linear                     | 590 K \n",
      "17 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key         | Linear                     | 590 K \n",
      "18 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value       | Linear                     | 590 K \n",
      "19 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dropout     | Dropout                    | 0     \n",
      "20 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense       | Linear                     | 590 K \n",
      "21 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm   | LayerNorm                  | 1 K   \n",
      "22 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn                   | Linear                     | 2 M   \n",
      "23 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output            | Linear                     | 2 M   \n",
      "24 | model.albert.pooler                                                              | Linear                     | 590 K \n",
      "25 | model.albert.pooler_activation                                                   | Tanh                       | 0     \n",
      "26 | model.qa_outputs                                                                 | Linear                     | 1 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3313ef0c857847e887c8036c35bffa5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83caa980127f4f2e8ce79e762a1a13cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443f5408be6745a88fbf228a3fc95ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37833ab7920145d2b929dc5994f2615b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(tweet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                                                                             | Type                       | Params\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "0  | model                                                                            | AlbertForQuestionAnswering | 11 M  \n",
      "1  | model.albert                                                                     | AlbertModel                | 11 M  \n",
      "2  | model.albert.embeddings                                                          | AlbertEmbeddings           | 3 M   \n",
      "3  | model.albert.embeddings.word_embeddings                                          | Embedding                  | 3 M   \n",
      "4  | model.albert.embeddings.position_embeddings                                      | Embedding                  | 65 K  \n",
      "5  | model.albert.embeddings.token_type_embeddings                                    | Embedding                  | 256   \n",
      "6  | model.albert.embeddings.LayerNorm                                                | LayerNorm                  | 256   \n",
      "7  | model.albert.embeddings.dropout                                                  | Dropout                    | 0     \n",
      "8  | model.albert.encoder                                                             | AlbertTransformer          | 7 M   \n",
      "9  | model.albert.encoder.embedding_hidden_mapping_in                                 | Linear                     | 99 K  \n",
      "10 | model.albert.encoder.albert_layer_groups                                         | ModuleList                 | 7 M   \n",
      "11 | model.albert.encoder.albert_layer_groups.0                                       | AlbertLayerGroup           | 7 M   \n",
      "12 | model.albert.encoder.albert_layer_groups.0.albert_layers                         | ModuleList                 | 7 M   \n",
      "13 | model.albert.encoder.albert_layer_groups.0.albert_layers.0                       | AlbertLayer                | 7 M   \n",
      "14 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm | LayerNorm                  | 1 K   \n",
      "15 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention             | AlbertAttention            | 2 M   \n",
      "16 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query       | Linear                     | 590 K \n",
      "17 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key         | Linear                     | 590 K \n",
      "18 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value       | Linear                     | 590 K \n",
      "19 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dropout     | Dropout                    | 0     \n",
      "20 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense       | Linear                     | 590 K \n",
      "21 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm   | LayerNorm                  | 1 K   \n",
      "22 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn                   | Linear                     | 2 M   \n",
      "23 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output            | Linear                     | 2 M   \n",
      "24 | model.albert.pooler                                                              | Linear                     | 590 K \n",
      "25 | model.albert.pooler_activation                                                   | Tanh                       | 0     \n",
      "26 | model.qa_outputs                                                                 | Linear                     | 1 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503b8216e2d44c23a736b42a571a0354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder = trainer.lr_find(tweet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': [1e-08,\n",
       "  1.4454397707459274e-08,\n",
       "  1.7378008287493753e-08,\n",
       "  2.0892961308540398e-08,\n",
       "  2.51188643150958e-08,\n",
       "  3.019951720402016e-08,\n",
       "  3.630780547701014e-08,\n",
       "  4.36515832240166e-08,\n",
       "  5.248074602497726e-08,\n",
       "  6.309573444801934e-08,\n",
       "  7.585775750291837e-08,\n",
       "  9.120108393559096e-08,\n",
       "  1.0964781961431852e-07,\n",
       "  1.3182567385564074e-07,\n",
       "  1.5848931924611133e-07,\n",
       "  1.9054607179632475e-07,\n",
       "  2.2908676527677735e-07,\n",
       "  2.7542287033381663e-07,\n",
       "  3.311311214825911e-07,\n",
       "  3.9810717055349735e-07,\n",
       "  4.786300923226383e-07,\n",
       "  5.75439937337157e-07,\n",
       "  6.918309709189366e-07,\n",
       "  8.317637711026709e-07,\n",
       "  1e-06,\n",
       "  1.2022644346174132e-06,\n",
       "  1.445439770745928e-06,\n",
       "  1.7378008287493761e-06,\n",
       "  2.089296130854039e-06,\n",
       "  2.5118864315095797e-06,\n",
       "  3.0199517204020163e-06,\n",
       "  3.630780547701014e-06,\n",
       "  4.365158322401661e-06,\n",
       "  5.248074602497728e-06,\n",
       "  6.3095734448019305e-06,\n",
       "  7.585775750291836e-06,\n",
       "  9.120108393559096e-06,\n",
       "  1.0964781961431852e-05,\n",
       "  1.3182567385564076e-05,\n",
       "  1.584893192461114e-05,\n",
       "  1.9054607179632464e-05,\n",
       "  2.2908676527677725e-05,\n",
       "  2.7542287033381663e-05,\n",
       "  3.311311214825911e-05,\n",
       "  3.9810717055349735e-05,\n",
       "  4.786300923226385e-05,\n",
       "  5.7543993733715664e-05,\n",
       "  6.918309709189363e-05,\n",
       "  8.317637711026709e-05,\n",
       "  0.0001,\n",
       "  0.00012022644346174131,\n",
       "  0.0001445439770745928,\n",
       "  0.00017378008287493763,\n",
       "  0.0002089296130854041,\n",
       "  0.0002511886431509582,\n",
       "  0.0003019951720402019,\n",
       "  0.000363078054770101,\n",
       "  0.0004365158322401656,\n",
       "  0.0005248074602497723,\n",
       "  0.000630957344480193,\n",
       "  0.0007585775750291836,\n",
       "  0.0009120108393559097,\n",
       "  0.0010964781961431851,\n",
       "  0.0013182567385564075,\n",
       "  0.001584893192461114,\n",
       "  0.0019054607179632484,\n",
       "  0.0022908676527677745,\n",
       "  0.002754228703338169,\n",
       "  0.003311311214825908,\n",
       "  0.003981071705534969,\n",
       "  0.00478630092322638,\n",
       "  0.005754399373371567,\n",
       "  0.006918309709189364,\n",
       "  0.008317637711026709,\n",
       "  0.01,\n",
       "  0.012022644346174132,\n",
       "  0.01445439770745928,\n",
       "  0.017378008287493765,\n",
       "  0.02089296130854041,\n",
       "  0.025118864315095822,\n",
       "  0.030199517204020192,\n",
       "  0.036307805477010104,\n",
       "  0.04365158322401657,\n",
       "  0.05248074602497723,\n",
       "  0.0630957344480193,\n",
       "  0.07585775750291836,\n",
       "  0.09120108393559097,\n",
       "  0.10964781961431852,\n",
       "  0.13182567385564073,\n",
       "  0.15848931924611143,\n",
       "  0.19054607179632482,\n",
       "  0.2290867652767775,\n",
       "  0.2754228703338169,\n",
       "  0.3311311214825908,\n",
       "  0.3981071705534969,\n",
       "  0.47863009232263803,\n",
       "  0.5754399373371567,\n",
       "  0.6918309709189363,\n",
       "  0.8317637711026709,\n",
       "  1.0],\n",
       " 'loss': [4.852814197540283,\n",
       "  4.8711871185688,\n",
       "  4.876705221376714,\n",
       "  4.862134102736493,\n",
       "  4.857629298407099,\n",
       "  4.863948692217515,\n",
       "  4.861378716460806,\n",
       "  4.85489430922122,\n",
       "  4.858595530492717,\n",
       "  4.855719952954582,\n",
       "  4.857937687393484,\n",
       "  4.8588587550934035,\n",
       "  4.858915925113151,\n",
       "  4.855735156575751,\n",
       "  4.851931281317224,\n",
       "  4.855176668640832,\n",
       "  4.8558900107012795,\n",
       "  4.854854659969428,\n",
       "  4.8571147176762155,\n",
       "  4.858685568141154,\n",
       "  4.856886971403008,\n",
       "  4.852660975762225,\n",
       "  4.852965880631312,\n",
       "  4.8517530957857895,\n",
       "  4.85493436392271,\n",
       "  4.855822318824287,\n",
       "  4.856418603056083,\n",
       "  4.852961945349571,\n",
       "  4.851898391863352,\n",
       "  4.853005068778618,\n",
       "  4.852990043469006,\n",
       "  4.855316362036063,\n",
       "  4.854136222464212,\n",
       "  4.853092965808918,\n",
       "  4.851098841794536,\n",
       "  4.848406144853146,\n",
       "  4.848552503637329,\n",
       "  4.847896568982436,\n",
       "  4.8512895418981055,\n",
       "  4.8493932621896985,\n",
       "  4.847096561414877,\n",
       "  4.845743420318874,\n",
       "  4.8434259836559495,\n",
       "  4.84124251713043,\n",
       "  4.839958699206426,\n",
       "  4.8407906383125265,\n",
       "  4.836874000331582,\n",
       "  4.835114199407724,\n",
       "  4.834016478218507,\n",
       "  4.830390838884867,\n",
       "  4.828054441372943,\n",
       "  4.825311106251531,\n",
       "  4.821362229680635,\n",
       "  4.815021071553982,\n",
       "  4.808755506786677,\n",
       "  4.800514395347506,\n",
       "  4.793709513227863,\n",
       "  4.780774314392964,\n",
       "  4.765935690708214,\n",
       "  4.748802323571938,\n",
       "  4.728936339500776,\n",
       "  4.705217532758188,\n",
       "  4.6784724837877905,\n",
       "  4.646618969474003,\n",
       "  4.6095819733282895,\n",
       "  4.569144165492666,\n",
       "  4.526303971076826,\n",
       "  4.475470473238021,\n",
       "  4.419194213816557,\n",
       "  4.363232563448719,\n",
       "  4.3068765614637945,\n",
       "  4.250415772660738,\n",
       "  4.191548955708665,\n",
       "  4.132351515552371,\n",
       "  4.073391371711905,\n",
       "  4.011979052938207,\n",
       "  3.9579144701650537,\n",
       "  3.8979306344677513,\n",
       "  3.8471717405535713,\n",
       "  3.7985684665779034,\n",
       "  3.752063532069565,\n",
       "  3.703675458876986,\n",
       "  3.654098182486417,\n",
       "  3.6039763076516005,\n",
       "  3.5599075005316374,\n",
       "  3.529294892044898,\n",
       "  3.4889354665012857,\n",
       "  3.4557436838306193,\n",
       "  3.4370149556397327,\n",
       "  3.4061388301131768,\n",
       "  3.3788285667513067,\n",
       "  3.339489676090815,\n",
       "  3.305886371867381,\n",
       "  3.285784637590797,\n",
       "  3.282073673083335,\n",
       "  3.277293816220397,\n",
       "  3.3104324657443156,\n",
       "  3.345658831507428,\n",
       "  3.380457345707983,\n",
       "  3.4147562463381473]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_finder.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = lr_finder.plot(suggest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_finder.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "\n",
      "   | Name                                                                             | Type                       | Params\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "0  | model                                                                            | AlbertForQuestionAnswering | 11 M  \n",
      "1  | model.albert                                                                     | AlbertModel                | 11 M  \n",
      "2  | model.albert.embeddings                                                          | AlbertEmbeddings           | 3 M   \n",
      "3  | model.albert.embeddings.word_embeddings                                          | Embedding                  | 3 M   \n",
      "4  | model.albert.embeddings.position_embeddings                                      | Embedding                  | 65 K  \n",
      "5  | model.albert.embeddings.token_type_embeddings                                    | Embedding                  | 256   \n",
      "6  | model.albert.embeddings.LayerNorm                                                | LayerNorm                  | 256   \n",
      "7  | model.albert.embeddings.dropout                                                  | Dropout                    | 0     \n",
      "8  | model.albert.encoder                                                             | AlbertTransformer          | 7 M   \n",
      "9  | model.albert.encoder.embedding_hidden_mapping_in                                 | Linear                     | 99 K  \n",
      "10 | model.albert.encoder.albert_layer_groups                                         | ModuleList                 | 7 M   \n",
      "11 | model.albert.encoder.albert_layer_groups.0                                       | AlbertLayerGroup           | 7 M   \n",
      "12 | model.albert.encoder.albert_layer_groups.0.albert_layers                         | ModuleList                 | 7 M   \n",
      "13 | model.albert.encoder.albert_layer_groups.0.albert_layers.0                       | AlbertLayer                | 7 M   \n",
      "14 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm | LayerNorm                  | 1 K   \n",
      "15 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention             | AlbertAttention            | 2 M   \n",
      "16 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query       | Linear                     | 590 K \n",
      "17 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key         | Linear                     | 590 K \n",
      "18 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value       | Linear                     | 590 K \n",
      "19 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dropout     | Dropout                    | 0     \n",
      "20 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense       | Linear                     | 590 K \n",
      "21 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm   | LayerNorm                  | 1 K   \n",
      "22 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn                   | Linear                     | 2 M   \n",
      "23 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output            | Linear                     | 2 M   \n",
      "24 | model.albert.pooler                                                              | Linear                     | 590 K \n",
      "25 | model.albert.pooler_activation                                                   | Tanh                       | 0     \n",
      "26 | model.qa_outputs                                                                 | Linear                     | 1 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf4176f61f44b47884eb33c341cfb5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad17787e98c43528dc480a52e48a01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04407c1ddcd45c98c490f0ff42e897a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6754d6637942c680e4692d8ee267da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77944f2605254650bb9a3b32097109a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_model = TweetModel(hparams)\n",
    "finetune_model(tweet_model, 5)\n",
    "\n",
    "name = 'albert'\n",
    "logger = TensorBoardLogger(\n",
    "                save_dir='ts-logs',\n",
    "                name = name\n",
    "            )\n",
    "if not os.path.exists('saved_models'):\n",
    "    os.mkdir('saved_models')\n",
    "if not os.path.exists(f'saved_models/{name}'):\n",
    "    os.mkdir(f'saved_models/{name}')\n",
    "checkpoint_callback = ModelCheckpoint(f'saved_models/{name}', save_top_k=2)\n",
    "early_stopping = EarlyStopping(monitor='val_jaccard')\n",
    "\n",
    "tweet_model.cuda()\n",
    "trainer = pl.Trainer(max_epochs=10,\n",
    "                     checkpoint_callback=checkpoint_callback,\n",
    "                     logger=logger,\n",
    "                    early_stop_callback=early_stopping,\n",
    "                    auto_lr_find=False)\n",
    "trainer.fit(tweet_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change to val_loss for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_ = torch.load('saved_models/albert/epoch=2.ckpt')\n",
    "tweet_model.load_state_dict(ckpt_['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TweetModel(\n",
       "  (model): AlbertForQuestionAnswering(\n",
       "    (albert): AlbertModel(\n",
       "      (embeddings): AlbertEmbeddings(\n",
       "        (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 128)\n",
       "        (token_type_embeddings): Embedding(2, 128)\n",
       "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (encoder): AlbertTransformer(\n",
       "        (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "        (albert_layer_groups): ModuleList(\n",
       "          (0): AlbertLayerGroup(\n",
       "            (albert_layers): ModuleList(\n",
       "              (0): AlbertLayer(\n",
       "                (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (attention): AlbertAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0, inplace=False)\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                )\n",
       "                (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (pooler_activation): Tanh()\n",
       "    )\n",
       "    (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "name = 'albert'\n",
    "logger = TensorBoardLogger(\n",
    "                save_dir='ts-logs',\n",
    "                name = name\n",
    "            )\n",
    "checkpoint_callback = ModelCheckpoint(f'saved_models/{name}', save_top_k=2)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                              patience=5)\n",
    "\n",
    "tweet_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "\n",
      "   | Name                                                                             | Type                       | Params\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "0  | model                                                                            | AlbertForQuestionAnswering | 11 M  \n",
      "1  | model.albert                                                                     | AlbertModel                | 11 M  \n",
      "2  | model.albert.embeddings                                                          | AlbertEmbeddings           | 3 M   \n",
      "3  | model.albert.embeddings.word_embeddings                                          | Embedding                  | 3 M   \n",
      "4  | model.albert.embeddings.position_embeddings                                      | Embedding                  | 65 K  \n",
      "5  | model.albert.embeddings.token_type_embeddings                                    | Embedding                  | 256   \n",
      "6  | model.albert.embeddings.LayerNorm                                                | LayerNorm                  | 256   \n",
      "7  | model.albert.embeddings.dropout                                                  | Dropout                    | 0     \n",
      "8  | model.albert.encoder                                                             | AlbertTransformer          | 7 M   \n",
      "9  | model.albert.encoder.embedding_hidden_mapping_in                                 | Linear                     | 99 K  \n",
      "10 | model.albert.encoder.albert_layer_groups                                         | ModuleList                 | 7 M   \n",
      "11 | model.albert.encoder.albert_layer_groups.0                                       | AlbertLayerGroup           | 7 M   \n",
      "12 | model.albert.encoder.albert_layer_groups.0.albert_layers                         | ModuleList                 | 7 M   \n",
      "13 | model.albert.encoder.albert_layer_groups.0.albert_layers.0                       | AlbertLayer                | 7 M   \n",
      "14 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm | LayerNorm                  | 1 K   \n",
      "15 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention             | AlbertAttention            | 2 M   \n",
      "16 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query       | Linear                     | 590 K \n",
      "17 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key         | Linear                     | 590 K \n",
      "18 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value       | Linear                     | 590 K \n",
      "19 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dropout     | Dropout                    | 0     \n",
      "20 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense       | Linear                     | 590 K \n",
      "21 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm   | LayerNorm                  | 1 K   \n",
      "22 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn                   | Linear                     | 2 M   \n",
      "23 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output            | Linear                     | 2 M   \n",
      "24 | model.albert.pooler                                                              | Linear                     | 590 K \n",
      "25 | model.albert.pooler_activation                                                   | Tanh                       | 0     \n",
      "26 | model.qa_outputs                                                                 | Linear                     | 1 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676b280f95044c8c80ab670f57ff005e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245b56c3c26647c6bf2189bca26c5435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e642688f704e62b4b5748a2bd22964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc3557946784096946564fed7551a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3bf43085d34ddea783c2fa1ad56a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=10,\n",
    "                     checkpoint_callback=checkpoint_callback,\n",
    "                     logger=logger,\n",
    "                    early_stop_callback=early_stopping,\n",
    "                    auto_lr_find=False)\n",
    "trainer.fit(tweet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592898"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_trainable_params(tweet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_model(tweet_model,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight\n",
      "model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias\n",
      "model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight\n",
      "model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias\n",
      "model.albert.pooler.weight\n",
      "model.albert.pooler.bias\n",
      "model.qa_outputs.weight\n",
      "model.qa_outputs.bias\n"
     ]
    }
   ],
   "source": [
    "print_trainable_params(tweet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                                                                             | Type                       | Params\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "0  | model                                                                            | AlbertForQuestionAnswering | 11 M  \n",
      "1  | model.albert                                                                     | AlbertModel                | 11 M  \n",
      "2  | model.albert.embeddings                                                          | AlbertEmbeddings           | 3 M   \n",
      "3  | model.albert.embeddings.word_embeddings                                          | Embedding                  | 3 M   \n",
      "4  | model.albert.embeddings.position_embeddings                                      | Embedding                  | 65 K  \n",
      "5  | model.albert.embeddings.token_type_embeddings                                    | Embedding                  | 256   \n",
      "6  | model.albert.embeddings.LayerNorm                                                | LayerNorm                  | 256   \n",
      "7  | model.albert.embeddings.dropout                                                  | Dropout                    | 0     \n",
      "8  | model.albert.encoder                                                             | AlbertTransformer          | 7 M   \n",
      "9  | model.albert.encoder.embedding_hidden_mapping_in                                 | Linear                     | 99 K  \n",
      "10 | model.albert.encoder.albert_layer_groups                                         | ModuleList                 | 7 M   \n",
      "11 | model.albert.encoder.albert_layer_groups.0                                       | AlbertLayerGroup           | 7 M   \n",
      "12 | model.albert.encoder.albert_layer_groups.0.albert_layers                         | ModuleList                 | 7 M   \n",
      "13 | model.albert.encoder.albert_layer_groups.0.albert_layers.0                       | AlbertLayer                | 7 M   \n",
      "14 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm | LayerNorm                  | 1 K   \n",
      "15 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention             | AlbertAttention            | 2 M   \n",
      "16 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query       | Linear                     | 590 K \n",
      "17 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key         | Linear                     | 590 K \n",
      "18 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value       | Linear                     | 590 K \n",
      "19 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dropout     | Dropout                    | 0     \n",
      "20 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense       | Linear                     | 590 K \n",
      "21 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm   | LayerNorm                  | 1 K   \n",
      "22 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn                   | Linear                     | 2 M   \n",
      "23 | model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output            | Linear                     | 2 M   \n",
      "24 | model.albert.pooler                                                              | Linear                     | 590 K \n",
      "25 | model.albert.pooler_activation                                                   | Tanh                       | 0     \n",
      "26 | model.qa_outputs                                                                 | Linear                     | 1 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0037249ea5e54a7dab4f274100248ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early due to diverging loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.lr_finder._LRFinder at 0x7f5df96f4590>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.lr_find(tweet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=10,\n",
    "                     checkpoint_callback=checkpoint_callback,\n",
    "                     logger=logger,\n",
    "                    early_stop_callback=early_stopping,\n",
    "                    auto_lr_find=False)\n",
    "trainer.fit(tweet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hparams = dict(tokenizer=tokenizer,\n",
    "           train_df=train_df, \n",
    "           val_df=val_df,\n",
    "           lr=3e-5, batch_size=64,\n",
    "           n_workers=4)\n",
    "hparams = Namespace(**hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-12e8c6927de3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m tweet_model.load_from_checkpoint('saved_models/albert/epoch=4.ckpt',\n\u001b[0;32m----> 2\u001b[0;31m                                 hparams_file=hparams)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, tags_csv, hparam_overrides, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhparams_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m             \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhparams_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1582\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m                 \u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_hparams_from_tags_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "tweet_model.load_from_checkpoint('saved_models/albert/epoch=4.ckpt',\n",
    "                                hparams_file=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train, train.sentiment), start=1): \n",
    "    print(f'Fold: {fold}')\n",
    "\n",
    "    model = TweetModel()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=3e-5, betas=(0.9, 0.999))\n",
    "    criterion = loss_fn    \n",
    "    dataloaders_dict = get_train_val_loaders(train, train_idx, val_idx, batch_size)\n",
    "\n",
    "    train_model(\n",
    "        model, \n",
    "        dataloaders_dict,\n",
    "        criterion, \n",
    "        optimizer, \n",
    "        num_epochs,\n",
    "        f'roberta_char_level_fold{fold}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\n",
    "test['text'] = test['text'].astype(str)\n",
    "test_loader = get_test_loader(test)\n",
    "predictions = []\n",
    "models = []\n",
    "for fold in range(skf.n_splits):\n",
    "    model = TweetModel()\n",
    "    model.cuda()\n",
    "    model.load_state_dict(torch.load(f'roberta_fold{fold+1}.pth'))\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "\n",
    "for data in test_loader:\n",
    "    ids = data['ids'].cuda()\n",
    "    masks = data['masks'].cuda()\n",
    "    tweet = data['tweet']\n",
    "    offsets = data['offsets'].numpy()\n",
    "\n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "    for model in models:\n",
    "        with torch.no_grad():\n",
    "            output = model(ids, masks)\n",
    "            start_logits.append(torch.softmax(output[0], dim=1).cpu().detach().numpy())\n",
    "            end_logits.append(torch.softmax(output[1], dim=1).cpu().detach().numpy())\n",
    "\n",
    "    start_logits = np.mean(start_logits, axis=0)\n",
    "    end_logits = np.mean(end_logits, axis=0)\n",
    "    for i in range(len(ids)):    \n",
    "        start_pred = np.argmax(start_logits[i])\n",
    "        end_pred = np.argmax(end_logits[i])\n",
    "        if start_pred > end_pred:\n",
    "            pred = tweet[i]\n",
    "        else:\n",
    "            pred = get_selected_text(tweet[i], start_pred, end_pred, offsets[i])\n",
    "        predictions.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')\n",
    "sub_df['selected_text'] = predictions\n",
    "sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('!!!!', '!') if len(x.split())==1 else x)\n",
    "sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('..', '.') if len(x.split())==1 else x)\n",
    "sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('...', '.') if len(x.split())==1 else x)\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "sub_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
